#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
auto_pubmed_pmc_to_zotero.py

åŠŸèƒ½ï¼š
- ä½¿ç”¨å›ºå®šçš„ 10 ä¸ª TOPICï¼Œä» PubMed è‡ªåŠ¨æ£€ç´¢é³ç¿…ç›® + Vg ç­‰ç›¸å…³æ–‡çŒ®
- æ–°æ–‡çŒ®å†™å…¥ Zotero æŒ‡å®šå­é›†åˆï¼Œå¹¶æ‰“ä¸Š auto:pubmed + topic:XXX æ ‡ç­¾
- ä½¿ç”¨ auto_pubmed_state.json è®°å½•å·²å¤„ç† PMIDï¼Œé¿å…é‡å¤å¯¼å…¥
- æ”¯æŒå‘½ä»¤è¡Œå‚æ•°é…ç½®
- æ”¯æŒ GitHub Actions å®šæ—¶è¿è¡Œ

ä¾èµ–ï¼š
- requests
- ç¯å¢ƒå˜é‡ï¼šZOTERO_USER_ID, ZOTERO_API_KEY

ç‰ˆæœ¬ï¼šv5.0 - ä¼˜åŒ–ç‰ˆï¼Œæ”¯æŒ GitHub Actions
"""

import os
import sys
import json
import logging
import argparse
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import urllib3
import warnings

# ç¦ç”¨ SSL è­¦å‘Šï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰
warnings.filterwarnings('ignore', message='Unverified HTTPS request')
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ================= ç‰ˆæœ¬ä¿¡æ¯ =================
__version__ = "5.0.0"

# ================= æ—¥å¿—è®¾ç½® =================

def setup_logging(log_file: Optional[str] = None, verbose: bool = False):
    """é…ç½®æ—¥å¿—"""
    level = logging.DEBUG if verbose else logging.INFO

    handlers = [logging.StreamHandler(sys.stdout)]
    if log_file:
        handlers.append(logging.FileHandler(log_file, encoding='utf-8'))

    logging.basicConfig(
        level=level,
        format="%(asctime)s [%(levelname)s] %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
        handlers=handlers
    )
    return logging.getLogger(__name__)

# ================= NCBI & Zotero é…ç½® =================

ESEARCH_URL = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
ESUMMARY_URL = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi"

ZOTERO_USER_ID = os.environ.get("ZOTERO_USER_ID")
ZOTERO_API_KEY = os.environ.get("ZOTERO_API_KEY")

STATE_FILE = "auto_pubmed_state.json"

DEFAULT_DAYS_BACK = 30
DEFAULT_RETMAX = 200

# ================= åˆ›å»ºå¥å£®çš„ Session =================

def create_robust_session() -> requests.Session:
    """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶å’Œè¶…æ—¶é…ç½®çš„ Session"""
    session = requests.Session()

    # é…ç½®é‡è¯•ç­–ç•¥
    retry_strategy = Retry(
        total=3,
        backoff_factor=1,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["HEAD", "GET", "OPTIONS", "POST"]
    )

    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("http://", adapter)
    session.mount("https://", adapter)

    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    })

    return session

# åˆ›å»ºå…¨å±€ session
SESSION = create_robust_session()

# ================= å…³é”®è¯æ¨¡å— =================

LEP = '(Lepidoptera OR moth* OR butterfly* OR "silkworm" OR Bombyx OR Antheraea OR Samia OR Manduca OR Helicoverpa OR Spodoptera OR Cydia OR Ostrinia OR Galleria OR Hyphantria OR Grapholita OR Papilio OR Pieris OR Danaus OR Hyles OR Plutella OR Agrotis OR Mythimna)'

VG = '("vitellogenin" OR "vitellogenesis" OR "vitellin" OR "VgR" OR "vitellogenin receptor" OR "yolk protein" OR "yolk" OR "egg yolk" OR "fat body" OR "oocyte development" OR "oocyte maturation" OR "vitellogenic stage" OR "vitellogenic oocyte")'

HORM = '("juvenile hormone" OR JH OR methoprene OR Met OR Taiman OR "Kr-h1" OR ecdysone OR 20E OR "20-hydroxyecdysone" OR "ecdysteroid" OR EcR OR USP OR "Broad-Complex" OR Br-C OR "hormone receptor" OR "steroid hormones" OR "endocrine regulation" OR "steroid receptor" OR "gonadotropic" OR "gonadotrophic" OR insulin OR "insulin-like peptide" OR IIS OR TOR OR "JH esterase" OR "JH epoxide hydrolase" OR JHAMT OR neuroendocrine OR "steroidogenic pathway" OR "hormone signaling")'

HORM_20E = '(ecdysone OR 20E OR "20-hydroxyecdysone" OR "ecdysteroid" OR EcR OR USP OR "Broad-Complex" OR Br-C OR "steroid hormones" OR "steroid receptor" OR "steroidogenic pathway")'
HORM_JH = '("juvenile hormone" OR JH OR methoprene OR Met OR Taiman OR "Kr-h1" OR "JH esterase" OR "JH epoxide hydrolase" OR JHAMT)'

OVARY = '(panoistic OR meroistic OR telotrophic OR polytrophic OR ovariole* OR oogenesis OR ovary OR ovarian OR "oocyte maturation" OR "ovarian development" OR "ovarian follicle" OR germarium OR "nurse cell" OR "follicular epithelium" OR "chorion formation")'

REPRO = '(viviparity OR ovoviviparity OR oviparity OR parthenogenesis OR paedogenesis OR "reproductive strategy" OR "reproductive physiology" OR "reproductive diapause" OR "reproductive output" OR "mating behavior" OR "female reproduction" OR "male reproduction" OR "egg production" OR "egg laying" OR oviposition OR fecundity OR fertility)'

LIFE = '("life history" OR "life-history" OR lifehistory OR "life span" OR longevity OR "developmental duration" OR "development time" OR "postembryonic development" OR metamorphosis OR "pupal stage" OR "larval stage" OR "adult longevity" OR "reproductive lifespan" OR diapause OR "seasonal reproduction")'

DIET = '("feeding behavior" OR "adult feeding" OR "feeding ecology" OR diet OR "nutritional regulation" OR "nutrient signaling" OR "sugar feeding" OR "nectar feeding" OR "amino acid" OR "lipid metabolism" OR "carbohydrate metabolism" OR "feeding adaptation" OR "nutritional stress" OR "nutrient limitation")'

EXCLUDE = 'NOT (Drosophila OR Diptera OR bee OR Apis OR Hymenoptera OR beetle OR Coleoptera OR mosquito OR Aedes OR Anopheles OR locust OR Orthoptera OR Blattodea OR human OR mouse OR rat OR mammal OR plant OR fish OR bacteria OR virus OR yeast OR fungus OR turtle OR snake OR cannabis)'

# ================= TOPIC é…ç½® =================

TOPICS: List[Dict] = [
    {
        "name": "PMC_20Eonly_Vg_Lep",
        "collection": "V6WK5UBC",
        "query": f"{LEP} AND {VG} AND {HORM_20E} AND {EXCLUDE}",
    },
    {
        "name": "PMC_JHonly_Vg_Lep",
        "collection": "V7BG9W57",
        "query": f"{LEP} AND {VG} AND {HORM_JH} AND {EXCLUDE}",
    },
    {
        "name": "PMC_LifeHistory_Vg_Lep",
        "collection": "A44KVBVZ",
        "query": f"{LEP} AND {VG} AND {LIFE} AND {EXCLUDE}",
    },
    {
        "name": "PMC_Ovary_Repro_Vg_Lep",
        "collection": "FX77FAZX",
        "query": f"{LEP} AND {VG} AND {OVARY} AND {REPRO} AND {EXCLUDE}",
    },
    {
        "name": "PMC_Nutrition_Hormone_Vg_Lep",
        "collection": "658NHUVA",
        "query": f"{LEP} AND {VG} AND {DIET} AND {HORM} AND {EXCLUDE}",
    },
    {
        "name": "PMC_Hormone_LifeHistory_Lep",
        "collection": "XR58SBTF",
        "query": f"{LEP} AND {HORM} AND {LIFE} AND {EXCLUDE}",
    },
    {
        "name": "PMC_Hormone_Ovary_Lep",
        "collection": "4SPN8P38",
        "query": f"{LEP} AND {HORM} AND {OVARY} AND {EXCLUDE}",
    },
    {
        "name": "PMC_Vg_ReproMode_Lep",
        "collection": "EMWGGGQM",
        "query": f"{LEP} AND {VG} AND {REPRO} AND {EXCLUDE}",
    },
    {
        "name": "PMC_Vg_Ovary_Lep",
        "collection": "5WVANIIZ",
        "query": f"{LEP} AND {VG} AND {OVARY} AND {EXCLUDE}",
    },
    {
        "name": "PMC_Vg_Hormone_Lep",
        "collection": "3JDKU2AH",
        "query": f"{LEP} AND {VG} AND {HORM} AND {EXCLUDE}",
    },
]

# ================= çŠ¶æ€è¯»å†™ =================

def load_state(state_file: str = STATE_FILE) -> Dict:
    if not os.path.exists(state_file):
        return {"last_run": None, "topics": {}}
    try:
        with open(state_file, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        logging.error("è¯»å– %s å¤±è´¥ï¼Œå°†é‡æ–°å¼€å§‹ï¼š%s", state_file, e)
        return {"last_run": None, "topics": {}}


def save_state(state: Dict, state_file: str = STATE_FILE) -> None:
    state["last_run"] = datetime.now().isoformat()
    try:
        with open(state_file, "w", encoding="utf-8") as f:
            json.dump(state, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logging.error("å†™å…¥ %s å¤±è´¥ï¼š%s", state_file, e)

# ================= PubMed æ£€ç´¢ & æ‘˜è¦ =================

def esearch_pubmed(term: str, days_back: int, retmax: int) -> List[str]:
    """åœ¨ PubMed ä¸­æ£€ç´¢ï¼Œè¿”å› PMID åˆ—è¡¨"""
    params = {
        "db": "pubmed",
        "retmode": "json",
        "retmax": retmax,
        "term": term,
        "reldate": days_back,
        "datetype": "pdat",
    }
    try:
        r = SESSION.get(ESEARCH_URL, params=params, timeout=60, verify=False, proxies={"http": None, "https": None})
        r.raise_for_status()
        data = r.json()
        idlist = data.get("esearchresult", {}).get("idlist", [])
        return idlist
    except requests.exceptions.RequestException as e:
        logging.error("PubMed æ£€ç´¢å¤±è´¥: %s", e)
        return []


def fetch_pubmed_summaries(pmids: List[str]) -> Dict[str, Dict]:
    """æ‰¹é‡è·å– PubMed ESummary"""
    if not pmids:
        return {}
    params = {
        "db": "pubmed",
        "retmode": "json",
        "id": ",".join(pmids),
    }
    try:
        r = SESSION.get(ESUMMARY_URL, params=params, timeout=60, verify=False, proxies={"http": None, "https": None})
        r.raise_for_status()
        data = r.json().get("result", {})
        summaries = {}
        for uid in data.get("uids", []):
            summaries[uid] = data.get(uid, {})
        return summaries
    except requests.exceptions.RequestException as e:
        logging.error("è·å– PubMed æ‘˜è¦å¤±è´¥: %s", e)
        return {}

# ================= Zotero å†™å…¥ =================

def make_zotero_item(pmid: str, summary: Dict, topic_name: str, collection_key: str) -> Dict:
    title = summary.get("title", f"PMID {pmid}")
    journal = summary.get("fulljournalname", "")
    pubdate = summary.get("pubdate", "")
    volume = summary.get("volume", "")
    issue = summary.get("issue", "")
    pages = summary.get("pages", "")

    item = {
        "itemType": "journalArticle",
        "title": title,
        "creators": [],
        "abstractNote": "",
        "publicationTitle": journal,
        "volume": volume,
        "issue": issue,
        "pages": pages,
        "date": pubdate,
        "series": "",
        "seriesTitle": "",
        "seriesText": "",
        "journalAbbreviation": "",
        "language": "",
        "DOI": "",
        "ISSN": "",
        "shortTitle": "",
        "url": f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/",
        "accessDate": "",
        "archive": "",
        "archiveLocation": "",
        "libraryCatalog": "PubMed",
        "callNumber": "",
        "rights": "",
        "extra": f"PMID: {pmid}",
        "tags": [
            {"tag": "auto:pubmed"},
            {"tag": f"topic:{topic_name}"},
        ],
        "collections": [],
        "relations": {},
    }
    return item


def push_to_zotero(items: List[Dict], dry_run: bool = False) -> int:
    if not items:
        return 0

    if dry_run:
        logging.info("  [é¢„è§ˆæ¨¡å¼] å°†å†™å…¥ %d æ¡ç›®åˆ° Zoteroï¼ˆæœªå®é™…æ‰§è¡Œï¼‰", len(items))
        return len(items)

    if not ZOTERO_USER_ID or not ZOTERO_API_KEY:
        logging.error("æœªé…ç½® ZOTERO_USER_ID æˆ– ZOTERO_API_KEY ç¯å¢ƒå˜é‡")
        return 0

    zotero_items_url = f"https://api.zotero.org/users/{ZOTERO_USER_ID}/items"
    headers = {
        "Zotero-API-Key": ZOTERO_API_KEY,
        "Content-Type": "application/json",
    }
    try:
        r = SESSION.post(zotero_items_url, headers=headers, data=json.dumps(items), timeout=60, verify=False, proxies={"http": None, "https": None})
        if r.status_code in (200, 201):
            logging.info("æˆåŠŸå†™å…¥ %d æ¡ç›®åˆ° Zotero", len(items))
            return len(items)
        else:
            logging.error("å†™å…¥ Zotero å¤±è´¥ï¼ŒHTTP %s: %s", r.status_code, r.text[:500])
            return 0
    except requests.exceptions.Timeout:
        logging.error("å†™å…¥ Zotero è¶…æ—¶")
        return 0
    except requests.exceptions.RequestException as e:
        logging.error("å†™å…¥ Zotero è¯·æ±‚å¤±è´¥: %s", e)
        return 0

# ================= å•ä¸ª TOPIC å¤„ç† =================

def process_topic(topic: Dict, state: Dict, days_back: int, retmax: int, dry_run: bool = False) -> Tuple[int, int, int]:
    name = topic["name"]
    collection = topic["collection"]
    query = topic["query"]

    topic_state = state.setdefault("topics", {}).setdefault(name, {"processed_pmids": []})
    processed: List[str] = topic_state.get("processed_pmids", [])
    processed_set = set(processed)

    logging.info("=== ä¸»é¢˜: %s ===", name)
    logging.debug("  Query: %s", query[:100] + "...")

    pmids = esearch_pubmed(query, days_back=days_back, retmax=retmax)
    total_found = len(pmids)
    logging.info("  å·²è®°å½•çš„ PMID æ•°: %d", len(processed_set))
    logging.info("  [PubMed] æ£€ç´¢: days_back=%d, retmax=%d", days_back, retmax)
    logging.info("  PubMed è¿”å› PMID æ•°: %d", total_found)

    new_pmids = [p for p in pmids if p not in processed_set]
    if not new_pmids:
        logging.info("  æ²¡æœ‰æ–°çš„ PMIDï¼ˆéƒ½å·²å¤„ç†è¿‡ï¼‰")
        return total_found, 0, 0

    logging.info("  æœ¬æ¬¡æ–°çš„ PMID æ•°: %d", len(new_pmids))

    summaries = fetch_pubmed_summaries(new_pmids)
    items = []
    for pmid in new_pmids:
        summary = summaries.get(pmid, {})
        items.append(make_zotero_item(pmid, summary, name, collection))

    written = push_to_zotero(items, dry_run=dry_run)

    if written > 0 and not dry_run:
        topic_state["processed_pmids"] = processed + new_pmids
        topic_state["last_update"] = datetime.now().isoformat()
        logging.info("  æœ¬æ¬¡æˆåŠŸå†™å…¥ Zotero æ¡ç›®æ•°: %d", written)
    elif dry_run:
        logging.info("  [é¢„è§ˆæ¨¡å¼] æœ¬æ¬¡å°†å†™å…¥ Zotero æ¡ç›®æ•°: %d", written)
    else:
        logging.info("  æœ¬æ¬¡æ²¡æœ‰æˆåŠŸå†™å…¥ Zotero æ¡ç›®")

    return total_found, len(new_pmids), written

# ================= çŠ¶æ€æŸ¥çœ‹ =================

def show_status(state: Dict):
    """æ˜¾ç¤ºé‡‡é›†çŠ¶æ€"""
    print("\n" + "=" * 60)
    print("ğŸ“Š è®ºæ–‡é‡‡é›†çŠ¶æ€")
    print("=" * 60)

    last_run = state.get("last_run", "ä»æœªè¿è¡Œ")
    print(f"\næœ€åè¿è¡Œæ—¶é—´: {last_run}")

    topics_state = state.get("topics", {})
    if not topics_state:
        print("\næš‚æ— é‡‡é›†è®°å½•")
        return

    print(f"\n{'ä¸»é¢˜åç§°':<35} {'å·²é‡‡é›†':<10} {'æœ€åæ›´æ–°':<20}")
    print("-" * 65)

    total_collected = 0
    for topic in TOPICS:
        name = topic["name"]
        topic_data = topics_state.get(name, {})
        count = len(topic_data.get("processed_pmids", []))
        last_update = topic_data.get("last_update", "-")
        if last_update != "-":
            last_update = last_update[:10]  # åªæ˜¾ç¤ºæ—¥æœŸéƒ¨åˆ†
        print(f"{name:<35} {count:<10} {last_update:<20}")
        total_collected += count

    print("-" * 65)
    print(f"{'æ€»è®¡':<35} {total_collected:<10}")
    print("=" * 60 + "\n")

# ================= åˆ—å‡ºä¸»é¢˜ =================

def list_topics():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨ä¸»é¢˜"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ å¯ç”¨ä¸»é¢˜åˆ—è¡¨")
    print("=" * 60)

    for i, topic in enumerate(TOPICS, 1):
        print(f"\n{i}. {topic['name']}")
        print(f"   Collection: {topic['collection']}")

    print("\n" + "=" * 60 + "\n")

# ================= å‘½ä»¤è¡Œå‚æ•°è§£æ =================

def parse_args():
    parser = argparse.ArgumentParser(
        description='PubMed to Zotero è‡ªåŠ¨é‡‡é›†å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s                          # ä½¿ç”¨é»˜è®¤é…ç½®è¿è¡Œ
  %(prog)s --days 7                 # æ£€ç´¢æœ€è¿‘ 7 å¤©çš„è®ºæ–‡
  %(prog)s --topic PMC_Vg_Hormone_Lep  # åªå¤„ç†æŒ‡å®šä¸»é¢˜
  %(prog)s --dry-run                # é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…å†™å…¥
  %(prog)s --status                 # æŸ¥çœ‹é‡‡é›†çŠ¶æ€
  %(prog)s --list-topics            # åˆ—å‡ºæ‰€æœ‰ä¸»é¢˜
        """
    )

    parser.add_argument('--days', type=int, default=DEFAULT_DAYS_BACK,
                        help=f'æ£€ç´¢æœ€è¿‘å¤šå°‘å¤©çš„è®ºæ–‡ (é»˜è®¤: {DEFAULT_DAYS_BACK})')
    parser.add_argument('--retmax', type=int, default=DEFAULT_RETMAX,
                        help=f'æ¯ä¸ªä¸»é¢˜æœ€å¤šæ£€ç´¢å¤šå°‘æ¡ (é»˜è®¤: {DEFAULT_RETMAX})')
    parser.add_argument('--topic', type=str, metavar='NAME',
                        help='åªå¤„ç†æŒ‡å®šçš„ä¸»é¢˜')
    parser.add_argument('--dry-run', action='store_true',
                        help='é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…å†™å…¥ Zotero')
    parser.add_argument('--status', action='store_true',
                        help='æ˜¾ç¤ºé‡‡é›†çŠ¶æ€')
    parser.add_argument('--list-topics', action='store_true',
                        help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨ä¸»é¢˜')
    parser.add_argument('--output', type=str, metavar='FILE',
                        help='è¾“å‡ºç»“æœåˆ° JSON æ–‡ä»¶')
    parser.add_argument('--state-file', type=str, default=STATE_FILE,
                        help=f'çŠ¶æ€æ–‡ä»¶è·¯å¾„ (é»˜è®¤: {STATE_FILE})')
    parser.add_argument('--log-file', type=str, metavar='FILE',
                        help='æ—¥å¿—è¾“å‡ºåˆ°æ–‡ä»¶')
    parser.add_argument('--verbose', '-v', action='store_true',
                        help='æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—')
    parser.add_argument('--version', action='version', version=f'%(prog)s {__version__}')

    return parser.parse_args()

# ================= ä¸»ç¨‹åº =================

def main():
    args = parse_args()

    # è®¾ç½®æ—¥å¿—
    logger = setup_logging(log_file=args.log_file, verbose=args.verbose)

    # åŠ è½½çŠ¶æ€
    state = load_state(args.state_file)

    # å¤„ç†ç‰¹æ®Šå‘½ä»¤
    if args.status:
        show_status(state)
        return 0

    if args.list_topics:
        list_topics()
        return 0

    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not args.dry_run and (not ZOTERO_USER_ID or not ZOTERO_API_KEY):
        logger.warning("âš  æœªæ£€æµ‹åˆ° ZOTERO_USER_ID / ZOTERO_API_KEY ç¯å¢ƒå˜é‡")
        logger.warning("  è¯·è®¾ç½®ç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨ --dry-run é¢„è§ˆæ¨¡å¼")

    # ç¡®å®šè¦å¤„ç†çš„ä¸»é¢˜
    topics_to_process = TOPICS
    if args.topic:
        topics_to_process = [t for t in TOPICS if t["name"] == args.topic]
        if not topics_to_process:
            logger.error("æœªæ‰¾åˆ°ä¸»é¢˜: %s", args.topic)
            logger.info("ä½¿ç”¨ --list-topics æŸ¥çœ‹æ‰€æœ‰å¯ç”¨ä¸»é¢˜")
            return 1

    # å¼€å§‹é‡‡é›†
    logger.info("=" * 60)
    logger.info("ğŸš€ è‡ªåŠ¨ PubMed -> Zotero é‡‡é›†å¼€å§‹")
    logger.info("=" * 60)
    logger.info("é…ç½®: days=%d, retmax=%d, dry_run=%s", args.days, args.retmax, args.dry_run)
    logger.info("å¤„ç†ä¸»é¢˜æ•°: %d", len(topics_to_process))

    # é‡‡é›†ç»“æœç»Ÿè®¡
    results = {
        "run_time": datetime.now().isoformat(),
        "config": {
            "days": args.days,
            "retmax": args.retmax,
            "dry_run": args.dry_run,
        },
        "topics": [],
        "summary": {
            "total_found": 0,
            "total_new": 0,
            "total_written": 0,
        }
    }

    for topic in topics_to_process:
        total, new_n, written = process_topic(
            topic, state,
            days_back=args.days,
            retmax=args.retmax,
            dry_run=args.dry_run
        )

        results["topics"].append({
            "name": topic["name"],
            "found": total,
            "new": new_n,
            "written": written,
        })
        results["summary"]["total_found"] += total
        results["summary"]["total_new"] += new_n
        results["summary"]["total_written"] += written

        logger.info("%s: æ£€ç´¢=%d, æ–°çš„=%d, å†™å…¥=%d", topic["name"], total, new_n, written)

    # ä¿å­˜çŠ¶æ€
    if not args.dry_run:
        save_state(state, args.state_file)
        logger.info("çŠ¶æ€å·²ä¿å­˜åˆ° %s", args.state_file)

    # è¾“å‡ºç»“æœ
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        logger.info("ç»“æœå·²è¾“å‡ºåˆ° %s", args.output)

    # æ‰“å°æ€»ç»“
    logger.info("=" * 60)
    logger.info("ğŸ“Š é‡‡é›†å®Œæˆ")
    logger.info("  æ€»æ£€ç´¢: %d", results["summary"]["total_found"])
    logger.info("  æ–°è®ºæ–‡: %d", results["summary"]["total_new"])
    logger.info("  å·²å†™å…¥: %d", results["summary"]["total_written"])
    logger.info("=" * 60)

    return 0


if __name__ == "__main__":
    sys.exit(main())
